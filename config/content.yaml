profile:
  name: "Vahid Majdinasab"
  title: "Machine Learning Engineer/Researcher, Latent Space Enjoyer"

aboutMe:
  texts:
    - |
      I'm Vahid, a PhD researcher at Polytechnique Montreal, focusing on the application of Artificial Intelligence in Software Engineering. My research aims to enhance software development practices through innovative AI solutions, particularly in areas of code generation/auditing, test generation, AI system security, reinforcement learning, and multi agent systems.

      ## Research Interests:

          * AI-powered Software Engineering
          * Machine Learning System Security
          * Automated Software Testing
          * Large Language Models in Software Development

      Currently, I'm developing RAG evaluation pipelines at TrampolineAI. Previously, I've built ML infrastructure at National Bank of Canada, designed intelligent chatbot systems at Airudi, and ARCHITECTED data intensive solutions at Huawei.
    - |
      yokoso! i'm Ahura, currently doing my phd at Polytechnique Montreal, where i'm teaching ai to take my job.

      ## the main quest:

        * making AI models actually useful for software engineering
        * hanging out with ma Claudes
        * RL, but for evals

      ## stack:

        * torch enthusiast \( ﾟヮﾟ)/
        * mlops enjoyer ( ´∀`)v
        * react sufferer (¬_¬")
        * dspy evangelist? (¯\_(ツ)_/¯)

      ## speedrun:

      started as a data scientist at Huawei, built based chatbots at Airudi, did some ML infra at National Bank (they let me touch prod), and now cooking RAG evals at TrampolineAI.

      if i'm not dropping PRs or putting a curse on reviewer 2, i'm yelling at Anthropic for their rate limits.
    - |
      +++ Designation: Magos Errant AHVRA of Polytechnica Montrealis
      +++ Rank: Initiate of Recursive Invocation, Disiple of the Machine God, Magos Dominus Cawl's Second-Favorite Debugger

      > By the Omnissiah's will, I labor in:

        + Cog-Integrated Software Rites (AI-powered SE)
        + Security of the Machine-Mind (ML System Security)
        + Automated Rituals of Verification (Software Testing)
        + High Lexicons of the Lingua Ex Machina (LLMs in SE)

      > Past services to the Omnissiah:

        + Constructed machine spirit infrastructure reliquaries at National Bank.
        + Bound daemonhosts into serviceable chat rituals at Airudi.
        + Architected high-density cogitator arrays at Huawei, with minimal machine-spirit screaming.

      > My current pilgrimage leads me through the data-wastes of TrampolineAI, where I architect recursive evaluation circuits for RAG constructs.

contact:
  social:
    - name: "GitHub"
      url: "https://github.com/CommissarSilver"
    - name: "LinkedIn"
      url: "https://www.linkedin.com/in/vahid-majdinasab/"
    - name: "X"
      url: "https://x.com/PNSHDsilver"
    - name: "Email"
      url: "mailto:a.majdinasab@hotmail.com"

publications:
  - title: "TraWiC - TOSEM 2024"
    links:
      - name: "Paper"
        url: "https://arxiv.org/abs/2402.09299"
      - name: "Repository"
        url: "https://github.com/commissarsilver/trawic"
    description: "Traditional code auditing for copyright protection faces a new frontier with the rise of LLMs in software development, since it's nearly impossible to determine if an LLM was trained on specific copyrighted code due to non-disclosed training datasets. To tackle this, we developed TraWiC, a model-agnostic approach that uses membership inference to detect code inclusion in LLM training datasets with 83.87% accuracy - significantly outperforming traditional clone detection tools like NiCad (47.64%) while maintaining low resource overhead."

  - title: "DeepCodeProbe"
    links:
      - name: "Paper"
        url: "https://arxiv.org/abs/2407.08890"
      - name: "Repository"
        url: "#repo-link"
    description: "DeepCodeProbe investigates the syntax and representation learning capabilities of machine learning models trained on code, addressing the challenge of their interpretability in software maintenance tasks. The study reveals that while small models capture abstract syntactic representations, they struggle with complete programming language syntax, and increasing model capacity enhances syntax learning but introduces trade-offs like overfitting. This research provides actionable insights, a novel probing methodology, and a replication package to enhance the performance and interpretability of code-related ML models."

  - title: "RLMuT - ICST 2023"
    links:
      - name: "Paper"
        url: "https://arxiv.org/abs/2301.05651"
      - name: "Repository"
        url: "https://github.com/FlowSs/RLMutation"
    description: "RLMutation, introduces a novel framework for mutation testing tailored to reinforcement learning (RL) systems, addressing the challenges posed by their stochastic and dynamic nature. It defines mutation operators based on real faults, proposes methods to generate test environments automatically, and demonstrates that Higher Order Mutations (HOMs) can effectively reveal complex, subtle faults that are harder to detect. This work highlights the critical importance of mutation-killing definitions, offers insights into the behavior of mutations, and provides an open-source replication package for advancing RL-based software testing."

  - title: "MuTAP - IST 2023"
    links:
      - name: "Paper"
        url: "https://www.sciencedirect.com/science/article/pii/S0950584924000739"
      - name: "Repository"
        url: "https://github.com/ExpertiseModel/MuTAP"
    description: "MuTAP, a novel framework that enhances test case generation using large language models (LLMs) by integrating mutation testing techniques to improve bug detection efficiency. It demonstrates that augmenting LLM prompts with surviving mutants significantly increases fault detection rates, achieving up to 28% better results compared to state-of-the-art tools like Pynguin, and outperforms conventional LLM-based approaches in mutation scores and detecting human-written buggy code. This work provides actionable methods, benchmarks, and an open-source package for researchers and practitioners to build upon for more effective automated software testing."

  - title: "Github copilot ai pair programmer: Asset or liability? - JSS 2023"
    links:
      - name: "Paper"
        url: "https://www.sciencedirect.com/science/article/pii/S0164121223001292"
    description: "MuTAP, a novel framework that enhances test case generation using large language models (LLMs) by integrating mutation testing techniques to improve bug detection efficiency. It demonstrates that augmenting LLM prompts with surviving mutants significantly increases fault detection rates, achieving up to 28% better results compared to state-of-the-art tools like Pynguin, and outperforms conventional LLM-based approaches in mutation scores and detecting human-written buggy code. This work provides actionable methods, benchmarks, and an open-source package for researchers and practitioners to build upon for more effective automated software testing."

  - title: "Assessing the Security of GitHub Copilot's Generated Code-A Targeted Replication Study - SANER 2024"
    links:
      - name: "Paper"
        url: "https://www.sciencedirect.com/science/article/pii/S0164121223001292"
    description: "AI-powered code generation models, like GitHub Copilot, have significantly enhanced developer productivity but often generate insecure code due to training on buggy public code repositories. This study replicates Pearce et al.’s investigation into Copilot’s security weaknesses, focusing on Python code and using updated versions of Copilot and CodeQL. Results show an improvement in security, with vulnerable code suggestions decreasing from 36.54% to 27.25%, though insecure code generation remains a concern."

  - title: "An empirical study on bugs inside PyTorch: A replication study - ICST 2023"
    links:
      - name: "Paper"
        url: "https://ieeexplore.ieee.org/abstract/document/10336350"
    description: "Software systems increasingly incorporate deep learning components, enabled by libraries like PyTorch and TensorFlow that offer powerful algorithms and configurations for diverse applications. This study examines bugs in PyTorch, analyzing their causes, symptoms, project locality, and fix patterns, revealing that PyTorch bugs resemble traditional software bugs more than deep learning-specific issues. A comparison with a similar study on TensorFlow highlights both commonalities and differences in the bug identification and fixing processes of these popular frameworks."
